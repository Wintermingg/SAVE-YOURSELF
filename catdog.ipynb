{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6lqCtpz8hcvbjoqDWNdve"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "392QK913jdVO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드. as_supervised=True는 (이미지, 라벨) 튜플 형태로 데이터를 반환합니다.\n",
        "(train_ds, validation_ds, test_ds), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# 라벨 정보 확인 (고양이: 0, 개: 1)\n",
        "class_names = metadata.features['label'].names\n",
        "print(\"클래스 이름:\", class_names)\n",
        "\n",
        "# 데이터 개수 확인\n",
        "num_train_examples = metadata.splits['train[:80%]'].num_examples\n",
        "num_validation_examples = metadata.splits['train[80%:90%]'].num_examples\n",
        "num_test_examples = metadata.splits['train[90%:]'].num_examples\n",
        "\n",
        "print(f\"훈련 데이터 개수: {num_train_examples}\")\n",
        "print(f\"검증 데이터 개수: {num_validation_examples}\")\n",
        "print(f\"테스트 데이터 개수: {num_test_examples}\")"
      ],
      "metadata": {
        "id": "H0m8T0vXjpRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 이미지 크기 조절 및 정규화 함수\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# 데이터 파이프라인 생성\n",
        "# .map() : 모든 데이터에 함수를 적용\n",
        "# .cache() : 데이터를 메모리에 캐시하여 다음 에포크부터 속도 향상\n",
        "# .shuffle() : 데이터를 섞어서 과적합 방지\n",
        "# .batch() : 데이터를 배치 크기만큼 묶음\n",
        "# .prefetch() : 훈련 중인 데이터 외에 다음 데이터를 미리 준비하여 성능 향상\n",
        "train_batches = train_ds.map(format_image).cache().shuffle(num_train_examples).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "validation_batches = validation_ds.map(format_image).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_batches = test_ds.map(format_image).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5ajFZ_rSjqyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# 1. 데이터 증강 레이어 생성\n",
        "data_augmentation = Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "# 2. 사전 학습된 MobileNetV2 모델 불러오기 (분류기는 제외)\n",
        "conv_base = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                        include_top=False,\n",
        "                        weights='imagenet')\n",
        "\n",
        "# 3. 사전 학습된 모델의 가중치 동결\n",
        "conv_base.trainable = False\n",
        "\n",
        "# 4. 전체 모델 조립\n",
        "model = Sequential([\n",
        "    # 입력 이미지를 먼저 증강 레이어에 통과시킴\n",
        "    data_augmentation,\n",
        "    # 그 다음 사전 학습 모델에 통과시킴\n",
        "    conv_base,\n",
        "    # Flatten 대신 GlobalAveragePooling2D 사용 (과적합 방지에 더 효과적)\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    # 드롭아웃 레이어\n",
        "    layers.Dropout(0.5),\n",
        "    # 최종 분류기\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0kbQc7SjkZVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# val_loss를 지켜보다가 3번 연속으로 성능 향상이 없으면 학습을 중단\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_batches,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "8RIVTgSulBoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 학습 과정 시각화\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# 2. 최종 성능 평가 (한 번도 본 적 없는 테스트 데이터 사용)\n",
        "print(\"\\n[최종 테스트 평가]\")\n",
        "test_loss, test_accuracy = model.evaluate(test_batches)\n",
        "print(f\"테스트 손실 (Loss): {test_loss}\")\n",
        "print(f\"테스트 정확도 (Accuracy): {test_accuracy}\")"
      ],
      "metadata": {
        "id": "ozNlIG0f8lp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/solapi/solapi-python.git"
      ],
      "metadata": {
        "id": "TCXpxjlcWJ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import time\n",
        "import hmac\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "SOLAPI_API_KEY = 'API_KEY'           # 본인의 API Key\n",
        "SOLAPI_API_SECRET = 'API_SECRET_KEY'     # 본인의 API Secret\n",
        "SOLAPI_SENDER_NUMBER = 'SEND_PHONE_NUMBER'             # 인증받은 내 발신번호 ('-' 없이)\n",
        "MY_PHONE_NUMBER = 'MY_PHONE_NUMBER'                  # 문자를 받을 내 실제 전화번호 ('-' 없이)\n",
        "\n",
        "\n",
        "def get_iso_datetime():\n",
        "    \"\"\"ISO 8601 형식의 현재 시간 반환\"\"\"\n",
        "    return time.strftime('%Y-%m-%dT%H:%M:%S.000Z', time.gmtime())\n",
        "\n",
        "def get_signature(api_secret, salt, date):\n",
        "    \"\"\"HMAC-SHA256 시그니처 생성\"\"\"\n",
        "    uri = \"/messages/v4/send\"  # 반드시 전송 요청 uri를 입력해야 합니다\n",
        "    message = date + salt + uri\n",
        "    return hmac.new(api_secret.encode(), message.encode(), hashlib.sha256).hexdigest()\n",
        "\n",
        "def get_signature(api_secret, salt, date):\n",
        "    \"\"\"(수정) HMAC-SHA256 시그니처 생성\"\"\"\n",
        "    key = api_secret.encode()\n",
        "    # Solapi v4 API의 규칙은 date와 salt만으로 메시지를 구성합니다.\n",
        "    msg = (date + salt).encode()\n",
        "    return hmac.new(key, msg, hashlib.sha256).hexdigest()\n",
        "\n",
        "def send_solapi_message_raw(message_text):\n",
        "    \"\"\"(수정) 라이브러리 없이 지정된 내용으로 문자 메시지를 보내는 함수\"\"\"\n",
        "    try:\n",
        "        # --- Solapi API의 공식 인증 규칙 ---\n",
        "        salt = str(uuid.uuid4())\n",
        "        date = get_iso_datetime()\n",
        "        # 수정된 함수를 호출합니다.\n",
        "        signature = get_signature(SOLAPI_API_SECRET, salt, date)\n",
        "\n",
        "        # --- 요청 헤더 구성 ---\n",
        "        headers = {\n",
        "            'Authorization': f'HMAC-SHA256 ApiKey={SOLAPI_API_KEY},Date={date},salt={salt},signature={signature}',\n",
        "            'Content-Type': 'application/json; charset=utf-8'\n",
        "        }\n",
        "\n",
        "        # --- 요청 본문(Body) 구성 ---\n",
        "        data = {\n",
        "            \"message\": {\n",
        "                \"to\": MY_PHONE_NUMBER,\n",
        "                \"from\": SOLAPI_SENDER_NUMBER,\n",
        "                \"text\": message_text\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # --- API 요청 보내기 ---\n",
        "        url = \"https://api.solapi.com/messages/v4/send\"\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(\"문자 메시지 요청 성공:\", response.json())\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        # 오류 발생 시 더 자세한 내용을 출력하도록 수정\n",
        "        print(f\"문자 메시지 요청 실패 (HTTP 오류): {e.response.status_code}\")\n",
        "        print(f\"오류 내용: {e.response.json()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"문자 메시지 요청 실패 (기타 오류): {e}\")\n",
        "\n",
        "\n",
        "# --- 이미지 예측 코드는 이전과 동일합니다 ---\n",
        "\n",
        "# 1. 이미지 파일 경로 지정\n",
        "image_path = '/content/Test_cat.jpg'\n",
        "\n",
        "try:\n",
        "    # 2. 이미지 불러오기 및 전처리\n",
        "    img = image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    # 3. 모델로 예측 수행 (model 변수가 정의되어 있어야 함)\n",
        "    prediction = model.predict(img_array)\n",
        "    prediction_value = prediction[0][0]\n",
        "    print(f\"모델 예측 값: {prediction_value}\")\n",
        "\n",
        "    # 4. 결과 해석 및 Solapi 문자 발송\n",
        "    if prediction_value > 0.5:\n",
        "        print(\"✅ 모델 판단: '개'입니다. Solapi로 문자 메시지를 보냅니다!\")\n",
        "        sms_body = \"시스템에서 강아지가 감지되었습니다.\"\n",
        "        send_solapi_message_raw(sms_body) # <-- 라이브러리 없는 함수 호출\n",
        "    else:\n",
        "        print(\"✅ 모델 판단: '고양이'입니다. Solapi로 문자 메시지를 보냅니다!.\")\n",
        "        sms_body = \"시스템에서 고양이가 감지되었습니다.\"\n",
        "        send_solapi_message_raw(sms_body) # <-- 라이브러리 없는 함수 호출\n",
        "\n",
        "    # 5. 이미지 확인\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"오류: '{e.name}' 변수가 정의되지 않았습니다. 모델('model')이나 이미지 크기 변수가 있는지 확인해주세요.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: '{image_path}' 파일을 찾을 수 없습니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "qRBZaTgjQksV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}